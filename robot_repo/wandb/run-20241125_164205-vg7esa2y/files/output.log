==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1
   \\   /|    Num examples = 10,047 | Num Epochs = 25
O^O/ \_/ \    Batch size per device = 64 | Gradient Accumulation steps = 2
\        /    Total batch size = 128 | Total steps = 1,950
 "-____-"     Number of trainable parameters = 24,313,856
[34m[1mwandb[0m: [33mWARNING[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.
                                                                                                                       
{'loss': 2.5731, 'grad_norm': 0.3793783485889435, 'learning_rate': 2e-05, 'epoch': 0.01}
{'loss': 2.5713, 'grad_norm': 0.3769618570804596, 'learning_rate': 4e-05, 'epoch': 0.03}
{'loss': 2.6062, 'grad_norm': 0.3865067958831787, 'learning_rate': 6e-05, 'epoch': 0.04}
{'loss': 2.6087, 'grad_norm': 0.39142921566963196, 'learning_rate': 8e-05, 'epoch': 0.05}
{'loss': 2.6239, 'grad_norm': 0.43705376982688904, 'learning_rate': 0.0001, 'epoch': 0.06}
{'loss': 2.5732, 'grad_norm': 0.4576842486858368, 'learning_rate': 9.999993477704843e-05, 'epoch': 0.08}
{'loss': 2.46, 'grad_norm': 0.46974244713783264, 'learning_rate': 9.999973910836387e-05, 'epoch': 0.09}
{'loss': 2.3802, 'grad_norm': 0.4605541527271271, 'learning_rate': 9.999941299445679e-05, 'epoch': 0.1}
{'loss': 2.3268, 'grad_norm': 0.42783141136169434, 'learning_rate': 9.999895643617803e-05, 'epoch': 0.11}
{'loss': 2.2473, 'grad_norm': 0.3927423059940338, 'learning_rate': 9.999836943471867e-05, 'epoch': 0.13}
{'loss': 2.1784, 'grad_norm': 0.3883025050163269, 'learning_rate': 9.999765199161018e-05, 'epoch': 0.14}
{'loss': 2.1063, 'grad_norm': 0.41370928287506104, 'learning_rate': 9.999680410872429e-05, 'epoch': 0.15}
{'loss': 2.0531, 'grad_norm': 0.4173397719860077, 'learning_rate': 9.999582578827308e-05, 'epoch': 0.17}
{'loss': 2.0296, 'grad_norm': 0.439462810754776, 'learning_rate': 9.99947170328089e-05, 'epoch': 0.18}
{'loss': 1.9578, 'grad_norm': 0.43258872628211975, 'learning_rate': 9.99934778452244e-05, 'epoch': 0.19}
{'loss': 1.9392, 'grad_norm': 0.4060050845146179, 'learning_rate': 9.999210822875251e-05, 'epoch': 0.2}
{'loss': 1.8375, 'grad_norm': 0.35770878195762634, 'learning_rate': 9.999060818696644e-05, 'epoch': 0.22}
{'loss': 1.793, 'grad_norm': 0.319232314825058, 'learning_rate': 9.998897772377971e-05, 'epoch': 0.23}
{'loss': 1.7473, 'grad_norm': 0.32041674852371216, 'learning_rate': 9.998721684344603e-05, 'epoch': 0.24}
{'loss': 1.7282, 'grad_norm': 0.3060325086116791, 'learning_rate': 9.998532555055942e-05, 'epoch': 0.25}
{'loss': 1.7379, 'grad_norm': 0.23734959959983826, 'learning_rate': 9.99833038500541e-05, 'epoch': 0.27}
{'loss': 1.676, 'grad_norm': 0.20234297215938568, 'learning_rate': 9.998115174720449e-05, 'epoch': 0.28}
{'loss': 1.7025, 'grad_norm': 0.2073431760072708, 'learning_rate': 9.997886924762529e-05, 'epoch': 0.29}
{'loss': 1.6787, 'grad_norm': 0.19733700156211853, 'learning_rate': 9.997645635727136e-05, 'epoch': 0.31}
{'loss': 1.729, 'grad_norm': 0.20368385314941406, 'learning_rate': 9.997391308243769e-05, 'epoch': 0.32}
{'loss': 1.6329, 'grad_norm': 0.20921148359775543, 'learning_rate': 9.99712394297595e-05, 'epoch': 0.33}
{'loss': 1.613, 'grad_norm': 0.20142053067684174, 'learning_rate': 9.996843540621215e-05, 'epoch': 0.34}
{'loss': 1.6823, 'grad_norm': 0.18030071258544922, 'learning_rate': 9.996550101911107e-05, 'epoch': 0.36}
{'loss': 1.606, 'grad_norm': 0.20830890536308289, 'learning_rate': 9.996243627611187e-05, 'epoch': 0.37}
{'loss': 1.6323, 'grad_norm': 0.17560380697250366, 'learning_rate': 9.995924118521017e-05, 'epoch': 0.38}
{'loss': 1.6269, 'grad_norm': 0.15043942630290985, 'learning_rate': 9.995591575474175e-05, 'epoch': 0.39}
{'loss': 1.6426, 'grad_norm': 0.15990647673606873, 'learning_rate': 9.995245999338234e-05, 'epoch': 0.41}
{'loss': 1.6176, 'grad_norm': 0.17210707068443298, 'learning_rate': 9.994887391014779e-05, 'epoch': 0.42}
{'loss': 1.6332, 'grad_norm': 0.15002578496932983, 'learning_rate': 9.994515751439385e-05, 'epoch': 0.43}
{'loss': 1.5783, 'grad_norm': 0.13927870988845825, 'learning_rate': 9.994131081581632e-05, 'epoch': 0.45}
{'loss': 1.6131, 'grad_norm': 0.14408741891384125, 'learning_rate': 9.993733382445091e-05, 'epoch': 0.46}
{'loss': 1.6092, 'grad_norm': 0.15220344066619873, 'learning_rate': 9.993322655067326e-05, 'epoch': 0.47}
{'loss': 1.5693, 'grad_norm': 0.15924473106861115, 'learning_rate': 9.992898900519893e-05, 'epoch': 0.48}
{'loss': 1.5862, 'grad_norm': 0.14457431435585022, 'learning_rate': 9.99246211990833e-05, 'epoch': 0.5}
{'loss': 1.6261, 'grad_norm': 0.13168303668498993, 'learning_rate': 9.992012314372164e-05, 'epoch': 0.51}
{'loss': 1.588, 'grad_norm': 0.13247857987880707, 'learning_rate': 9.991549485084901e-05, 'epoch': 0.52}
{'loss': 1.6131, 'grad_norm': 0.14386050403118134, 'learning_rate': 9.991073633254024e-05, 'epoch': 0.54}
{'loss': 1.6152, 'grad_norm': 0.14880430698394775, 'learning_rate': 9.99058476012099e-05, 'epoch': 0.55}
{'loss': 1.5791, 'grad_norm': 0.15236513316631317, 'learning_rate': 9.990082866961232e-05, 'epoch': 0.56}
{'loss': 1.5872, 'grad_norm': 0.14415858685970306, 'learning_rate': 9.989567955084145e-05, 'epoch': 0.57}
{'loss': 1.5738, 'grad_norm': 0.15164361894130707, 'learning_rate': 9.989040025833094e-05, 'epoch': 0.59}
{'loss': 1.5322, 'grad_norm': 0.17126931250095367, 'learning_rate': 9.988499080585402e-05, 'epoch': 0.6}
{'loss': 1.5667, 'grad_norm': 0.16722214221954346, 'learning_rate': 9.987945120752352e-05, 'epoch': 0.61}
{'loss': 1.5688, 'grad_norm': 0.16015209257602692, 'learning_rate': 9.987378147779178e-05, 'epoch': 0.62}
{'loss': 1.5285, 'grad_norm': 0.17292675375938416, 'learning_rate': 9.986798163145068e-05, 'epoch': 0.64}
{'loss': 1.5708, 'grad_norm': 0.1859385073184967, 'learning_rate': 9.986205168363154e-05, 'epoch': 0.65}
{'loss': 1.5455, 'grad_norm': 0.20434145629405975, 'learning_rate': 9.98559916498051e-05, 'epoch': 0.66}
{'loss': 1.5339, 'grad_norm': 0.21186242997646332, 'learning_rate': 9.98498015457815e-05, 'epoch': 0.68}
{'loss': 1.5745, 'grad_norm': 0.20583289861679077, 'learning_rate': 9.98434813877102e-05, 'epoch': 0.69}
{'loss': 1.5736, 'grad_norm': 0.2249078005552292, 'learning_rate': 9.983703119207999e-05, 'epoch': 0.7}
{'loss': 1.5609, 'grad_norm': 0.23861438035964966, 'learning_rate': 9.98304509757189e-05, 'epoch': 0.71}
{'loss': 1.5534, 'grad_norm': 0.27342087030410767, 'learning_rate': 9.982374075579416e-05, 'epoch': 0.73}
{'loss': 1.5641, 'grad_norm': 0.25548112392425537, 'learning_rate': 9.981690054981219e-05, 'epoch': 0.74}
{'loss': 1.5797, 'grad_norm': 0.28010737895965576, 'learning_rate': 9.980993037561854e-05, 'epoch': 0.75}
{'loss': 1.564, 'grad_norm': 0.29429516196250916, 'learning_rate': 9.980283025139783e-05, 'epoch': 0.76}
{'loss': 1.5418, 'grad_norm': 0.3658837676048279, 'learning_rate': 9.979560019567368e-05, 'epoch': 0.78}
{'loss': 1.5801, 'grad_norm': 0.3541469871997833, 'learning_rate': 9.978824022730871e-05, 'epoch': 0.79}
{'loss': 1.5239, 'grad_norm': 0.39714568853378296, 'learning_rate': 9.97807503655045e-05, 'epoch': 0.8}
{'loss': 1.4871, 'grad_norm': 0.4286954998970032, 'learning_rate': 9.977313062980146e-05, 'epoch': 0.82}
{'loss': 1.5443, 'grad_norm': 0.42176106572151184, 'learning_rate': 9.976538104007886e-05, 'epoch': 0.83}
{'loss': 1.51, 'grad_norm': 0.37347468733787537, 'learning_rate': 9.975750161655477e-05, 'epoch': 0.84}
{'loss': 1.51, 'grad_norm': 0.25158584117889404, 'learning_rate': 9.974949237978592e-05, 'epoch': 0.85}
{'loss': 1.5686, 'grad_norm': 0.1474996954202652, 'learning_rate': 9.97413533506678e-05, 'epoch': 0.87}
{'loss': 1.5763, 'grad_norm': 0.13307563960552216, 'learning_rate': 9.973308455043443e-05, 'epoch': 0.88}
{'loss': 1.5277, 'grad_norm': 0.13058429956436157, 'learning_rate': 9.972468600065846e-05, 'epoch': 0.89}
{'loss': 1.539, 'grad_norm': 0.12655985355377197, 'learning_rate': 9.971615772325098e-05, 'epoch': 0.9}
{'loss': 1.5288, 'grad_norm': 0.12560716271400452, 'learning_rate': 9.97074997404616e-05, 'epoch': 0.92}
{'loss': 1.5162, 'grad_norm': 0.13864551484584808, 'learning_rate': 9.96987120748783e-05, 'epoch': 0.93}
{'loss': 1.5228, 'grad_norm': 0.12586663663387299, 'learning_rate': 9.968979474942735e-05, 'epoch': 0.94}
{'loss': 1.4647, 'grad_norm': 0.1488117277622223, 'learning_rate': 9.968074778737333e-05, 'epoch': 0.96}
{'loss': 1.5415, 'grad_norm': 0.1272328794002533, 'learning_rate': 9.967157121231901e-05, 'epoch': 0.97}
{'loss': 1.5292, 'grad_norm': 0.14139430224895477, 'learning_rate': 9.966226504820534e-05, 'epoch': 0.98}
{'loss': 1.542, 'grad_norm': 0.12743496894836426, 'learning_rate': 9.965282931931134e-05, 'epoch': 0.99}
{'loss': 2.2063, 'grad_norm': 0.18980340659618378, 'learning_rate': 9.964326405025405e-05, 'epoch': 1.01}
{'loss': 1.4692, 'grad_norm': 0.13401620090007782, 'learning_rate': 9.963356926598847e-05, 'epoch': 1.02}
{'loss': 1.481, 'grad_norm': 0.12799936532974243, 'learning_rate': 9.962374499180751e-05, 'epoch': 1.03}
{'loss': 1.4899, 'grad_norm': 0.13171732425689697, 'learning_rate': 9.961379125334188e-05, 'epoch': 1.04}
{'loss': 1.4717, 'grad_norm': 0.11869741231203079, 'learning_rate': 9.960370807656007e-05, 'epoch': 1.06}
{'loss': 1.4708, 'grad_norm': 0.13160906732082367, 'learning_rate': 9.959349548776827e-05, 'epoch': 1.07}
{'loss': 1.5972, 'grad_norm': 0.14396195113658905, 'learning_rate': 9.95831535136103e-05, 'epoch': 1.08}
